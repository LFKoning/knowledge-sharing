{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7659cfd1",
   "metadata": {},
   "source": [
    "# Model Validation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644bbee",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the banking data set.\n",
    "df = pd.read_csv(\"../../0_data/banking/bank-additional-full.csv\", sep=\";\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c68267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels.\n",
    "X = df.drop(columns=[\"duration\", \"pdays\", \"y\"])\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b72a4",
   "metadata": {},
   "source": [
    "## Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74053783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names per data type.\n",
    "categorical = X.select_dtypes(\"object\").columns\n",
    "numerical = X.select_dtypes(\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the ColumnTransformer.\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"encode_categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "        (\"scale_numerical\", StandardScaler(), numerical),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f37f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model.\n",
    "dummy = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", DummyClassifier(strategy=\"stratified\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71843e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model.\n",
    "linear = Pipeline(\n",
    "    steps=[\n",
    "        (\"preparation\", transformer),\n",
    "        (\"model\", LogisticRegression(max_iter=500)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34230184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest model.\n",
    "forest = Pipeline(\n",
    "    steps=[\n",
    "        (\"preparation\", transformer),\n",
    "        (\"model\", RandomForestClassifier(n_jobs=-1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2a957",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12842812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the train set from the model.\n",
    "linear.fit(X, y)\n",
    "predictions = linear.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35869214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix.\n",
    "# Note: rows are actual, columns are predicted.\n",
    "conf_mtx = confusion_matrix(y, predictions)\n",
    "conf_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c84fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy score.\n",
    "accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2596e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check...\n",
    "tn, fp, fn, tp = conf_mtx.ravel()\n",
    "total = conf_mtx.sum()\n",
    "\n",
    "(tp + tn) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06387eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision score\n",
    "# Note: Percentage correctly predicted as positive.\n",
    "precision_score(y, predictions, pos_label=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccdec2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Double check...\n",
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall score\n",
    "# Note: Percentage correct from actual positive.\n",
    "recall_score(y, predictions, pos_label=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check...\n",
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a68041",
   "metadata": {},
   "source": [
    "## Train versus Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at the data.\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the labels.\n",
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the training data.\n",
    "linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ae117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for the training data.\n",
    "predictions_train = linear.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the training data.\n",
    "# Note: Accuracy on the training set is usually high.\n",
    "accuracy_score(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf09ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the test data.\n",
    "# Note: We do not re-fit the model!\n",
    "predictions_test = linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And accuracy on the test data.\n",
    "# Note: Accuracy is similar to the train data; no overfitting.\n",
    "accuracy_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25975059",
   "metadata": {},
   "source": [
    "## Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the models\n",
    "models = {\"dummy\": dummy, \"linear\": linear, \"random forest\": forest}\n",
    "chars = 45\n",
    "\n",
    "\n",
    "print(\"=\" * chars)\n",
    "for model_name, model in models.items():\n",
    "    # Train the model.\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions for the test set.\n",
    "    pred_train = model.predict(X_train) \n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Compute performance metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": (\n",
    "            accuracy_score(y_train, pred_train),\n",
    "            accuracy_score(y_test, pred_test)\n",
    "        ),\n",
    "        \"precision\": (\n",
    "            precision_score(y_train, pred_train, pos_label=\"yes\"),\n",
    "            precision_score(y_test, pred_test, pos_label=\"yes\")\n",
    "        ),\n",
    "        \"recall\": (\n",
    "            recall_score(y_train, pred_train, pos_label=\"yes\"),\n",
    "            recall_score(y_test, pred_test, pos_label=\"yes\")\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    # Print\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"-\" * chars)\n",
    "    for metric, (train, test) in metrics.items():\n",
    "          print(f\"{metric:20s}: {train:8.2f}    :  {test:8.2f}\")\n",
    "    print(\"=\" * chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175da394",
   "metadata": {},
   "source": [
    "## Most Uncertain Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc77e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and probabilities.\n",
    "linear.fit(X_train, y_train)\n",
    "predictions = linear.predict(X_test)\n",
    "probabilities = linear.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ff650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First label is \"no\".\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First probability corresponds to \"no\"\n",
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine everything into a DataFrame.\n",
    "analysis = (\n",
    "    X_test\n",
    "    .assign(\n",
    "        actual=y_test,\n",
    "        predicted=predictions,\n",
    "        probability_yes=probabilities[:, 1],\n",
    "    )\n",
    ")\n",
    "analysis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a34d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance to the decision boundary (= 0.5).\n",
    "# Note: Cases close to the decision boundary are \"uncertain\" / have low probability.\n",
    "analysis = analysis.assign(certainty=(0.5 - analysis[\"probability_yes\"]).abs() * 2)\n",
    "analysis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f38fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 most uncertain cases.\n",
    "analysis.sort_values(\"certainty\").head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most confident errors for \"yes\"\n",
    "(\n",
    "    analysis\n",
    "    \n",
    "    # Filter only wrong predictions.\n",
    "    .query(\"actual != predicted\")\n",
    "    \n",
    "    # Note: Set ascending=True to get most confident \"no\" errors.\n",
    "    .sort_values(\"probability_yes\", ascending=False)\n",
    "    \n",
    "    .head(8)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55d24c",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold object and specify splits.\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rotation of the test set.\n",
    "# Note: All other cases will end up in the train set.\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y), start=1):\n",
    "    print(f\"Fold {fold} -- Test cases:    {test_idx[0]:5d} - {test_idx[-1]:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01064fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"fold\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": []\n",
    "}\n",
    "model = linear\n",
    "\n",
    "# Perform cross-validation with 5 splits.\n",
    "kfold = KFold(n_splits=5)\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y), start=1):\n",
    "    \n",
    "    # Create data sets for the fold.\n",
    "    # Note: Must use .iloc[] because we have indices!\n",
    "    X_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "        \n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "        \n",
    "    # Train the model and get predictions\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Fold {fold} -- Predicted yes: \", (predictions == \"yes\").sum())\n",
    "        \n",
    "    # Compute and store performance metrics\n",
    "    metrics[\"fold\"].append(fold)\n",
    "    metrics[\"accuracy\"].append(accuracy_score(y_test, predictions))\n",
    "    metrics[\"precision\"].append(precision_score(y_test, predictions, pos_label=\"yes\"))\n",
    "    metrics[\"recall\"].append(recall_score(y_test, predictions, pos_label=\"yes\"))\n",
    "    \n",
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0206a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how \"yes\" labels are dispersed through the data.\n",
    "(\n",
    "    pd.DataFrame({\n",
    "        \"index\": df.index,\n",
    "        \"total_yes\": (df[\"y\"] == \"yes\").cumsum(),\n",
    "    })\n",
    "    .plot(\n",
    "        x=\"index\",\n",
    "        y=\"total_yes\",\n",
    "        title=\"Label: Yes - Cumulative\",\n",
    "        figsize=(10, 3),\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a153d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how campaigns in March are dispersed through the data.\n",
    "months = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "ax = (\n",
    "    pd.DataFrame({\n",
    "        \"index\": df.index,\n",
    "        \"month_num\": df[\"month\"].map(lambda m: months.index(m) + 1)\n",
    "    })\n",
    "    .plot(\n",
    "        x=\"index\",\n",
    "        y=\"month_num\",\n",
    "        title=\"Months\",\n",
    "        figsize=(10, 3),\n",
    "        legend=False,\n",
    "    )\n",
    ")\n",
    "ax.set_yticks([m + 1 for m in range(12)], months)\n",
    "ax.grid(visible=True, color=\"lightgrey\", axis=\"y\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how campaigns in March are dispersed through the data.\n",
    "ax = (\n",
    "    pd.DataFrame({\n",
    "        \"index\": df.index,\n",
    "        \"price_index\": df[\"cons.price.idx\"]\n",
    "    })\n",
    "    .plot(\n",
    "        x=\"index\",\n",
    "        y=\"price_index\",\n",
    "        title=\"Price Ixdex\",\n",
    "        figsize=(10, 3),\n",
    "        legend=False,\n",
    "    )\n",
    ")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56c6c9",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c236eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [50, 100, 150, 200, 250, 300]\n",
    "test_size = 1000\n",
    "model = forest\n",
    "\n",
    "results = {\n",
    "    \"train_size\": [],\n",
    "    \"train\": [],\n",
    "    \"test\": [],\n",
    "}\n",
    "for train_size in train_sizes:\n",
    "    \n",
    "    # Make the datas sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        train_size=train_size,\n",
    "        test_size=test_size,\n",
    "        shuffle=True,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Fit and compute accuracies\n",
    "    model.fit(X_train, y_train)\n",
    "    acc_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    acc_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Store results\n",
    "    results[\"train_size\"].append(train_size)\n",
    "    results[\"train\"].append(acc_train)\n",
    "    results[\"test\"].append(acc_test)\n",
    "    \n",
    "# Plot results\n",
    "(\n",
    "    pd.DataFrame(results)\n",
    "    .plot(\n",
    "        x=\"train_size\",\n",
    "        y=[\"train\", \"test\"],\n",
    "        marker=\".\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27d27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
