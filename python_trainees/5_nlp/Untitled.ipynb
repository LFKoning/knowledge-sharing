{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.component_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fd4ba",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fe838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target to match to.\n",
    "target = \"certain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7144057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define documents to match.\n",
    "docs = [\n",
    "    \"certain\",\n",
    "    \"sure\",\n",
    "    \"uncertain\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer to convert to numeric data.\n",
    "vectorizer = CountVectorizer().fit(docs)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the target.\n",
    "target_vector = vectorizer.transform([target])\n",
    "target_vector.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f57de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the documents.\n",
    "doc_vectors = vectorizer.transform(docs)\n",
    "doc_vectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd99c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities.\n",
    "for doc, doc_vector in zip(docs, doc_vectors):\n",
    "    similarity = cosine_similarity(target_vector, doc_vector)[0 ,0]\n",
    "    print(f\"Similarity {target} - {doc:10s} {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the target.\n",
    "target_vector = nlp(target).vector.reshape(1, -1)\n",
    "target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the documents.\n",
    "doc_vectors = [nlp(doc).vector.reshape(1, -1) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities.\n",
    "for doc, doc_vector in zip(docs, doc_vectors):\n",
    "    similarity = cosine_similarity(target_vector, doc_vector)[0 ,0]\n",
    "    print(f\"Similarity {target} - {doc:10s} {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nlp(\"certain sure uncertain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254413e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0].similarity(tmp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd9807",
   "metadata": {},
   "source": [
    "### Vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad62c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB review dataset.\n",
    "reviews = pd.read_csv(\"../0_data/imdb/imdb_reviews_small.csv\", compression=\"zip\")\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[[\"dataset\", \"label\"]].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f16869",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reviews.query(\"dataset == 'Train'\")[\"content\"]\n",
    "y_train = reviews.query(\"dataset == 'Train'\")[\"label\"]\n",
    "\n",
    "X_test = reviews.query(\"dataset == 'Test'\")[\"content\"]\n",
    "y_test = reviews.query(\"dataset == 'Test'\")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97749191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_vectors(dataset):\n",
    "    # Convert to Docs.\n",
    "    docs = nlp.pipe(\n",
    "        dataset,\n",
    "        n_process=3,\n",
    "        disable=[\n",
    "            'tagger',\n",
    "            'parser',\n",
    "            'senter',\n",
    "            'attribute_ruler',\n",
    "            'lemmatizer',\n",
    "            'ner'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return [doc.vector for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f87147",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_train = nlp_vectors(X_train)\n",
    "Xt_test = nlp_vectors(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdd27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27634c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, model.predict(Xt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, model.predict(Xt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e599edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f150d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv_train = vectorizer.fit_transform(X_train)\n",
    "Xv_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d03c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60432417",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(Xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d97490",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, rf.predict(Xv_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4910aac",
   "metadata": {},
   "source": [
    "### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd159367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_encode(pos, embed, n_embed, scale=10_000):\n",
    "    if embed % 2:\n",
    "        return np.cos(pos / scale ** ((embed - 1)/ n_embed))\n",
    "    return np.sin(pos / scale ** (embed / n_embed))\n",
    "    i = i - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04130f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = 6\n",
    "s_pos = 2\n",
    "n_embed = 4\n",
    "scale = 2\n",
    "\n",
    "\n",
    "x_draw = np.linspace(0, n_pos)\n",
    "x_points = np.array([_ for _ in range(n_pos)])\n",
    "\n",
    "fig, axes = plt.subplots(1, n_embed, figsize=(n_embed * 1.2, 2), sharex=True, sharey=True)\n",
    "for i in range(n_embed):\n",
    "\n",
    "    y_draw = pos_encode(x_draw, i, n_embed, scale)\n",
    "    y_points = pos_encode(x_points, i, n_embed, scale)\n",
    "\n",
    "    axes[i].plot(x_draw, y_draw)\n",
    "    axes[i].scatter(x_points, y_points, s=10)\n",
    "    axes[i].axvline(s_pos, color=\"orange\")\n",
    "    axes[i].annotate(f\"{y_points[s_pos]:.2f}\", (s_pos, -1))\n",
    "    axes[i].set_yticks([-1, 0, 1])\n",
    "\n",
    "# fig.supylabel('Embedding')\n",
    "# fig.supxlabel('Word Position')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea5ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
