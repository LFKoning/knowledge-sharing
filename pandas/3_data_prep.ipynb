{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from pprint import pprint\n",
    "from utils import record_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "n=100\n",
    "\n",
    "record = record_factory()\n",
    "sales = pd.DataFrame(data=[next(record) for _ in range(n)])\n",
    "sales.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugly, assigns column in place.\n",
    "sales[\"avg_order_amount\"] = sales[\"order_amount\"] / sales[\"orders\"]\n",
    "sales.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using assign method instead.\n",
    "# Supply <column name>=<column logic> as arguments.\n",
    "sales.assign(\n",
    "    avg_order_amount=sales[\"order_amount\"] / sales[\"orders\"],\n",
    "    age=(dt.date.today() - sales[\"birthdate\"]).dt.days,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No in-place modifications; age column is not in the orignal DataFrame.\n",
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also provide arguments using a dict.\n",
    "# Sometimes useful when automatically generating columns in a loop.\n",
    "assignments = {\n",
    "    \"avg_order_amount\": sales[\"order_amount\"] / sales[\"orders\"],\n",
    "    \"age\": (dt.date.today() - sales[\"birthdate\"]).dt.days,   \n",
    "}\n",
    "\n",
    "# Use **{...} to unroll the dict into arguments.\n",
    "sales = sales.assign(**assignments)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugly in-place assignment...\n",
    "sales[\"spender_type\"] = \"medium\"\n",
    "sales.loc[sales[\"order_amount\"] > 20, \"spender_type\"] = \"big\"\n",
    "sales.loc[sales[\"order_amount\"] < 10, \"spender_type\"] = \"small\"\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uhoh dreaded \"SettingWithCopyWarning\" (because we didn't use .loc[])\n",
    "sales[sales[\"order_amount\"] > 20][\"spender_type\"] = \"big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of the column\n",
    "sales = sales.drop(columns=\"spender_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better solution using .assign() and np.where(<cond>, <true statement>, <false statement>)\n",
    "(\n",
    "    sales\n",
    "    .assign(\n",
    "        spender_type=np.where(sales[\"order_amount\"] > 20, \"big\", \"small\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or simply use a function for conditional assignment.\n",
    "# Also allows you to document your classification in the docstring!\n",
    "def classify_spenders(amount):\n",
    "    \"\"\"Classifies your customers!\"\"\"\n",
    "    \n",
    "    if amount < 10:\n",
    "        return \"small\"\n",
    "    elif amount > 20:\n",
    "        return \"big\"\n",
    "    return \"medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .map() to apply your classification function to a column.\n",
    "# Note: if your function needs multiple columns; look into the .apply() method.\n",
    "(\n",
    "    sales\n",
    "    .assign(\n",
    "        spender_type=sales[\"order_amount\"].map(classify_spenders)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows: top 10 customers.\n",
    "# Note: due to the brackets () we can \"chain\" methods; one line for each operation.\n",
    "(\n",
    "    sales\n",
    "    .sort_values(\"order_amount\", ascending=False)\n",
    "    .loc[:, [\"first_name\", \"last_name\", \"city\", \"order_amount\"]]\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort on multiple columns using a list of column names.\n",
    "# Use a list to specify the sort order for each column.\n",
    "(\n",
    "    sales\n",
    "    .sort_values([\"city\", \"order_amount\"], ascending=[True, False])\n",
    "    .loc[:, [\"first_name\", \"last_name\", \"city\", \"order_amount\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by index instead of columns.\n",
    "sales.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .groupby() method creates DataFrameGroupBy object\n",
    "sales.groupby([\"city\", \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is basically a group to index values mapping.\n",
    "pprint(\n",
    "    sales.groupby([\"city\", \"gender\"]).groups\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can apply aggregation methods directly to the DataFrameGroupBy object.\n",
    "sales_agg = sales.groupby([\"city\", \"gender\"]).mean()\n",
    "sales_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, .groupby() creates a (multi-) index...\n",
    "# This can be tricky to use...\n",
    "sales_agg.loc[(\"Amsterdam\", ), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ugh...\n",
    "sales_agg.loc[(slice(None), \"male\"), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as_index=False to avoid automatic index creation!\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"], as_index=False)\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using agg / aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .agg() to specify column + aggregation method.\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"], as_index=False)\n",
    "    .agg({\n",
    "        \"age\": \"mean\",\n",
    "        \"order_amount\": \"mean\",\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a lost to specify multiple aggregations for a single column.\n",
    "sales_agg = (\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"], as_index=False)\n",
    "    .agg({\n",
    "        \"age\": \"mean\",\n",
    "        \"order_amount\": [\"mean\", \"min\", \"max\"],\n",
    "    })\n",
    ")\n",
    "sales_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes... another MultiIndex, but now on the columns...\n",
    "sales_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of it using set_axis\n",
    "# Note: not a very flexible solution...\n",
    "(\n",
    "    sales_agg\n",
    "    .set_axis(\n",
    "        [\"city\", \"gender\", \"age_mean\", \"order_amount_mean\", \"order_amount_min\", \"order_amount_max\"],\n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use a helper function to make it more flexible...\n",
    "def collapse_levels(df):\n",
    "    \"\"\"Collapse levels of a column multi-index.\"\"\"\n",
    "\n",
    "    colnames = [\"_\".join(t).strip(\"_\") for t in df.columns]\n",
    "    return df.set_axis(colnames, axis=1)\n",
    "\n",
    "\n",
    "# Using .pipe() to apply the function to the entire DataFrame.\n",
    "(\n",
    "    sales_agg\n",
    "    .pipe(collapse_levels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New style syntax for aggregations (pandas > 0.25).\n",
    "# Note: more similar to the assign syntax.\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"], as_index=False)\n",
    "    .agg(\n",
    "        age_mean=(\"age\", \"mean\"),\n",
    "        order_amount_mean=(\"order_amount\", \"mean\"),\n",
    "        order_amount_min=(\"order_amount\", \"min\"),\n",
    "        order_amount_max=(\"order_amount\", \"max\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_spenders(amount, threshold=20):\n",
    "    \"\"\"\n",
    "    Counts customers who spend more than threshold value.\n",
    "    Note: uses Series as input.\n",
    "    \"\"\"\n",
    "    \n",
    "    return amount[amount > threshold].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply custom aggregation to the grouped DataFrame.\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"])\n",
    "    .agg(\n",
    "        big_spenders=(\"order_amount\", big_spenders)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom aggregation with parameters using a lambda function.\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"])\n",
    "    .agg(\n",
    "        big_spenders=(\"order_amount\", lambda s: big_spenders(s, 10))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform method performs an aggregation \"in the background\" and maps the result onto the original index values. It thus creates a Series or DataFrame with the same index (and number of rows) as the one it was created from. This makes it easy to merge it with the original DataFrame. Note that it will (most likely) introduce duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with sales totals per city.\n",
    "# Note the index matches the sales DataFrame.\n",
    "# Also note the duplicate values for records of the same city.\n",
    "(\n",
    "    sales\n",
    "    .groupby(\"city\")\n",
    "    [\"order_amount\"]\n",
    "    .transform(\"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .assign() we can easily incorporate the city totals in the sales DataFrame.\n",
    "(\n",
    "    sales\n",
    "    .assign(\n",
    "        city_total=sales.groupby([\"city\", \"gender\"])[\"order_amount\"].transform(\"sum\")\n",
    "    )\n",
    "    .sort_values([\"city\", \"gender\"])\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the city total to calculate which percentage a customer contributed.\n",
    "(\n",
    "    sales\n",
    "    .assign(\n",
    "        city_total=lambda df: df.groupby([\"city\", \"gender\"])[\"order_amount\"].transform(\"sum\"),\n",
    "        city_percentage=lambda df: 100 * df[\"order_amount\"] / df[\"city_total\"],\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute percentage contributed in a different way.\n",
    "# Note that this function will receive a DataFrame for each group.\n",
    "\n",
    "def group_percentage(df):\n",
    "    \"\"\"Computes percentage sales contribution per group.\"\"\"\n",
    "    \n",
    "    city_total = df[\"order_amount\"].sum()\n",
    "    return df.assign(city_percentage=100 * df[\"order_amount\"] / city_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .apply() to apply the function to each group.\n",
    "# Note: we have a MultiIndex again... can drop it as the columns are also in the data.\n",
    "(\n",
    "    sales\n",
    "    .groupby([\"city\", \"gender\"])\n",
    "    .apply(group_percentage)\n",
    "    .sort_values(\"id\")\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join, Merge, and Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data sets\n",
    "a = pd.DataFrame({\"label_a\": list(\"ABC\")}, index=[1, 2, 3])\n",
    "b = pd.DataFrame({\"label_b\": list(\"ABD\")}, index=[1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join uses the indices to join two DataFrames.\n",
    "# Note: defaults to LEFT join.\n",
    "a.join(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available joins: \"left\", \"right\", \"inner\", \"outer\"\n",
    "a.join(b, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid duplicate column names when using .join()!\n",
    "a[\"x\"] = [1, 2, 3]\n",
    "b[\"x\"] = [1, 2, 3]\n",
    "\n",
    "a.join(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use the lsuffix / rsuffix arguments to resolve duplicate names.\n",
    "a.join(b, lsuffix=\"_left\", rsuffix=\"_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge resembles join, but uses columns instead of indices. It is also a bit more user-friendly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"x\": [1, 2, 3], \"label_a\": list(\"ABC\")})\n",
    "b = pd.DataFrame({\"x\": [1, 2, 4], \"label_b\": list(\"ABD\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple merge, automatically finds and uses shared columns.\n",
    "# Note: defaults to INNER join (cf. LEFT join from the join method).\n",
    "a.merge(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify join column with the on argument and join type with the how argument.\n",
    "a.merge(b, on=\"x\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on different columns in the left and right DataFrame.\n",
    "# Note: merge conveniently uses automatic suffixes!\n",
    "a.merge(b, left_on=\"label_a\", right_on=\"label_b\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"label_a\": list(\"ABC\")})\n",
    "b = pd.DataFrame({\"label_b\": list(\"ABD\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat resembles SQL UNION statement; it merges rows from 2 DataFrames.\n",
    "pd.concat([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use axis=1 to concatenate along column axis.\n",
    "pd.concat([a, b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat respects indices, note the introduced NaN values.\n",
    "a = pd.DataFrame({\"label_a\": list(\"ABC\")}, index=[1, 2, 3])\n",
    "b = pd.DataFrame({\"label_b\": list(\"ABD\")}, index=[1, 2, 4])\n",
    "\n",
    "pd.concat([a, b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter] *",
   "language": "python",
   "name": "conda-env-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
